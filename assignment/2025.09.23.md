## Assignment 8: Regularization for Preventing Overfitting

**Instructions:** Please provide detailed answers, including mathematical derivations where appropriate, for the following questions.

<br>

**Question 1: The Mathematics of Weight Decay**

The lecture notes state that L2 regularization is also known as "Weight Decay." Starting with the regularized loss function for L2 regularization:
$$
L_{reg} = L_{original} + \frac{\lambda}{2m} \sum_{i} w_i^2
$$
1.  Derive the partial derivative of $L_{reg}$ with respect to a single weight, $w_j$.
2.  Write out the full gradient descent update rule for $w_j$.
3.  Rearrange the terms in the update rule to show mathematically why this process is called "weight decay."

<br>

**Question 2: Understanding Dropout During Training vs. Testing**

Dropout behaves differently during the training and testing (inference) phases.
1.  Describe the key difference in the network's forward pass between these two phases.
2.  The notes mention that at test time, activations are scaled. Explain mathematically why this scaling is necessary. What would be the consequence of not performing this scaling?

<br>

**Question 3: Batch Normalization as a Regularizer**

The lecture explains that Batch Normalization's regularizing effect stems from the "noise introduced by the mini-batch statistics." Elaborate on this concept.
1.  Why are the mean and variance calculated by Batch Norm considered "noisy"?
2.  How does this noise help to regularize the model and prevent overfitting?

<br>

**Question 4: Choosing the Right Regularization Technique**

Suppose you have trained a model and, upon inspecting its weights, you find that a small number of neurons have extremely large weight values, while the vast majority have very small weights. This suggests the model is relying heavily on a few specific features.
Which regularization technique discussed in the lecture (L1, L2, or Dropout) would be most direct and effective at discouraging this specific behavior? Justify your choice and briefly explain why the other two might be less direct solutions to this particular problem.

<br>
<br>

## Solution Report: Assignment 8

Below are the detailed solutions for the assignment on regularization techniques.

<br>

### **Solution to Question 1: The Mathematics of Weight Decay**

**Problem Statement:** Derive the weight decay update rule from the L2 regularized loss function.

**Solution:**

1.  **Partial Derivative Derivation:**
    The regularized loss function is $L_{reg} = L_{original} + \frac{\lambda}{2m} \sum_{i} w_i^2$.
    We compute the partial derivative with respect to a single weight $w_j$:
    $$
    \frac{\partial L_{reg}}{\partial w_j} = \frac{\partial L_{original}}{\partial w_j} + \frac{\partial}{\partial w_j} \left( \frac{\lambda}{2m} \sum_{i} w_i^2 \right)
    $$
    The derivative of the summation term is zero for all $w_i$ where $i \neq j$. The only non-zero term is for $w_j^2$.
    $$
    \frac{\partial}{\partial w_j} \left( \frac{\lambda}{2m} \sum_{i} w_i^2 \right) = \frac{\lambda}{2m} \frac{\partial}{\partial w_j} (w_j^2) = \frac{\lambda}{2m} (2w_j) = \frac{\lambda}{m} w_j
    $$
    Therefore, the full partial derivative is:
    $$
    \frac{\partial L_{reg}}{\partial w_j} = \frac{\partial L_{original}}{\partial w_j} + \frac{\lambda}{m} w_j
    $$

2.  **Gradient Descent Update Rule:**
    The standard update rule is $w_j \leftarrow w_j - \eta \frac{\partial L_{reg}}{\partial w_j}$. Substituting our derivative gives:
    $$
    w_j \leftarrow w_j - \eta \left( \frac{\partial L_{original}}{\partial w_j} + \frac{\lambda}{m} w_j \right)
    $$

3.  **Demonstrating Weight Decay:**
    We can rearrange the terms from the update rule:
    $$
    w_j \leftarrow w_j - \eta \frac{\partial L_{original}}{\partial w_j} - \eta \frac{\lambda}{m} w_j
    $$
    Now, we group the terms containing $w_j$:
    $$
    w_j \leftarrow w_j \left( 1 - \frac{\eta \lambda}{m} \right) - \eta \frac{\partial L_{original}}{\partial w_j}
    $$
    This final form reveals the "weight decay" mechanism. Before performing the standard gradient update ($\eta \frac{\partial L_{original}}{\partial w_j}$), the current weight $w_j$ is multiplied by a factor of $\left( 1 - \frac{\eta \lambda}{m} \right)$. Since the learning rate $\eta$, regularization parameter $\lambda$, and batch size $m$ are all positive, this factor is slightly less than 1. Thus, at every single update step, the weight is first multiplicatively shrunk, or "decayed," toward zero before the gradient update is applied.

<br>

### **Solution to Question 2: Understanding Dropout During Training vs. Testing**

**Problem Statement:** Explain the difference in Dropout's behavior during training and testing and the necessity of scaling.

**Solution:**

1.  **Difference in Forward Pass:**
    -   **During Training:** For each forward pass, a fraction of neurons in a Dropout layer are randomly selected and deactivated (their output is set to zero). The selection of dropped neurons is different for each mini-batch.
    -   **During Testing (Inference):** No neurons are dropped out. The full, learned network is used to make predictions.

2.  **Necessity of Scaling:**
    Let's consider a layer with a "keep probability" $p$ (e.g., if dropout rate is 20%, $p=0.8$).
    During training, any given neuron is active with probability $p$. Therefore, the expected output of a layer is a summation over activations that are, on average, scaled by a factor of $p$.
    During testing, if we were to use all neurons without any modification, all neurons would be active. The total output of the layer would be, on average, $1/p$ times larger than the expected output during training. This significant change in the magnitude of activations would create a mismatch between the distributions the network learned to handle during training and what it sees during testing, leading to poor performance.

    To correct this, we must ensure the expected output of a layer is the same during training and testing. We achieve this by scaling the activations at test time. If a neuron has a learned activation of $a$, its output during testing is modified to be $p \cdot a$. This scaling ensures that the overall magnitude of the layer's output is consistent with what the subsequent layers expect from the training phase, allowing the model to generalize correctly. (Note: In modern implementations, "inverted dropout" is more common, where activations are scaled up by $1/p$ during training, which achieves the same goal without needing to modify the network at test time.)

<br>

### **Solution to Question 3: Batch Normalization as a Regularizer**

**Problem Statement:** Explain why the noise from mini-batch statistics in Batch Norm has a regularizing effect.

**Solution:**

1.  **Source of "Noise":**
    The mean and variance used by Batch Normalization to normalize a layer's pre-activations are calculated for each individual mini-batch, not over the entire dataset. A mini-batch is a small, random sample of the full training data. Due to this random sampling, the calculated mean and variance for a layer will fluctuate slightly from one mini-batch to the next. This fluctuation, which is dependent on the specific examples included in a batch, is the source of the "noise."

2.  **Regularizing Effect of Noise:**
    For any single training example, the exact normalization applied to its activations within the network will be slightly different each time it is seen, as it will be part of a different mini-batch with a different mean and variance. This process is a form of implicit data augmentation that occurs in the hidden layers. The network is constantly seeing slightly perturbed versions of the internal representations.

    This noise prevents the network from becoming too confident and memorizing the exact activation values for specific training examples. It forces the model to learn more robust features that are invariant to these small changes in the distribution of the preceding layer's activations. By making it harder for the model to fit the training data perfectly, this noisy normalization process discourages overfitting and improves the model's ability to generalize to new, unseen data.

<br>

### **Solution to Question 4: Choosing the Right Regularization Technique**

**Problem Statement:** Choose the best regularization technique to combat a model's reliance on a few very large weights.

**Solution:**

-   **Most Effective Technique:** **L2 Regularization**.
-   **Justification:** The L2 regularization penalty is the sum of the *squared* values of the weights ($\sum w_i^2$). The use of the square is critical here. It means that the penalty for a large weight is disproportionately larger than the penalty for a small weight. For example, a weight of 10 contributes 100 to the penalty, whereas a weight of 2 contributes only 4. This creates a strong gradient pressure to shrink very large weights, while having a much smaller effect on already small weights. The overall effect is to encourage the model to find a solution with a more distributed and "smoother" set of smaller weights, which directly counteracts the problem of relying on a few dominant features.

-   **Comparison with Other Techniques:**
    -   **L1 Regularization:** L1 regularization penalizes the sum of the absolute values of the weights ($\sum |w_i|$). While it would also penalize the large weights, its primary effect is encouraging sparsity by driving many weights to become exactly zero. It's more of a feature selection mechanism. While it would help, L2 is more directly targeted at simply reducing the magnitude of large weights without necessarily eliminating them.
    -   **Dropout:** Dropout provides an indirect solution. By randomly deactivating neurons, it prevents the model from becoming overly reliant on any single neuron's output. This would force the network to distribute the learning across more neurons, implicitly discouraging the development of a few massive weights. However, this is an indirect effect. L2 regularization directly targets the objective of minimizing the magnitude of the weight values themselves, making it the most direct and appropriate tool for this specific issue.