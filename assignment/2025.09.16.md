## Assignment 6: Optimization Techniques

**Question 1: The Role of Velocity in Momentum**

The lecture notes describe that standard gradient descent can perform poorly in ravines, oscillating across the narrow axis while making slow progress along the bottom.
Explain mathematically how the Momentum optimizer's update rule helps to mitigate this problem. Contrast the standard Gradient Descent update rule with the two equations for Momentum. How does the velocity term $v_t$ behave in a ravine where gradients frequently change direction along one axis but are consistent along another?

<br>

**Question 2: Deconstructing the Adam Update Rule**

The final update rule for Adam is:

$$
W \leftarrow W - \eta \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}
$$

Deconstruct this formula and explain the distinct roles of the numerator ($\hat{m}_t$) and the denominator ($\sqrt{\hat{v}_t}$). How does each part correspond to the core ideas of "momentum" and "adaptive learning rates"?

<br>

**Question 3: The Necessity of Bias Correction in Adam**

Adam's authors introduced bias correction terms for the first and second moment estimates:

$$
\hat{m}_t = \frac{m_t}{1 - \beta_1^t} \quad \text{and} \quad \hat{v}_t = \frac{v_t}{1 - \beta_2^t}
$$

Explain mathematically why the initial moment estimates, $m_t$ and $v_t$, are biased towards zero. Then, analyze the behavior of the correction factor (the denominator, $1 - \beta^t$) as the time step $t$ changes. Why is this correction most important during the initial stages of training?

<br>

**Question 4: The Impact of the Momentum Hyperparameter**

In the Momentum optimizer, the update for the velocity is $v_t = \gamma v_{t-1} + \eta \nabla_W L$. The hyperparameter $\gamma$ is the momentum term.
1.  What does the Momentum update rule simplify to if $\gamma = 0$?
2.  Describe the behavior of the optimizer if $\gamma$ is set to a value very close to 1 (e.g., 0.999). What are the potential benefits and drawbacks of such a high value, using the analogy of a ball rolling down a hill?

<br>
<br>

## Solution Report

### **Solution to Question 1: The Role of Velocity in Momentum**

**Problem Statement:** Explain how Momentum's update rule mitigates oscillations in ravines.

**Solution:**

The standard Gradient Descent (GD) update rule is:

$$
W \leftarrow W - \eta \nabla_W L
$$

This update is based solely on the gradient at the current position. In a ravine-shaped loss landscape, the gradient points steeply across the ravine but only shallowly along the bottom. As a result, GD takes large steps that bounce from one side of the ravine to the other, leading to oscillations and slow progress along the optimal path.

The Momentum optimizer uses two equations:
1.  $v_t = \gamma v_{t-1} + \eta \nabla_W L$
2.  $W \leftarrow W - v_t$

The key is the velocity vector $v_t$, which is an exponentially decaying moving average of past gradients. Let's analyze its behavior in a ravine:

-   **Axis of Oscillation (across the ravine):** The gradients along this axis will have alternating signs. For example, in one step the gradient might be `[+0.5, +0.01]` and in the next, `[-0.5, +0.01]`. The component of the gradient responsible for oscillation (+0.5, -0.5) will tend to cancel itself out over time in the moving average $v_t$. The friction term $\gamma$ ensures that the previous, opposing velocity component is dampened before the new gradient is added, smoothing out the oscillations.

-   **Axis of Progress (along the ravine):** The gradients along this axis will be small but consistent in sign (e.g., the `+0.01` component in the example above). Because these components always point in the same direction, they will consistently add to the velocity term $v_t$. Over several steps, these small, consistent gradients accumulate, building up speed and accelerating progress along the bottom of the ravine.

In summary, the momentum term $v_t$ averages out the oscillating gradient components while accumulating the consistent ones, effectively dampening the undesirable side-to-side movement and accelerating the desirable forward movement.

<br>

### **Solution to Question 2: Deconstructing the Adam Update Rule**

**Problem Statement:** Explain the roles of the numerator and denominator in the Adam update rule.

**Solution:**

The Adam update rule, $W \leftarrow W - \eta \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}$, elegantly combines two key concepts.

**1. The Numerator, $\hat{m}_t$ (Momentum):**
$\hat{m}_t$ is the bias-corrected estimate of the first moment (mean) of the gradients. Its update rule is $m_t = \beta_1 m_{t-1} + (1 - \beta_1) \nabla_W L$. This is an exponentially decaying moving average of the gradients, which is mathematically analogous to the velocity term $v_t$ in the Momentum optimizer.
-   **Role:** This term provides the "momentum" part of the update. It helps the optimizer accelerate in consistent directions and smooths out variations in the gradient, allowing it to navigate ravines and saddle points more effectively. It determines the direction and a scaled magnitude of the step.

**2. The Denominator, $\sqrt{\hat{v}_t}$ (Adaptive Learning Rate):**
$\hat{v}_t$ is the bias-corrected estimate of the second moment (uncentered variance) of the gradients. Its update rule is $v_t = \beta_2 v_{t-1} + (1 - \beta_2) (\nabla_W L)^2$. This term tracks the magnitude of recent gradients for each parameter. The update step is divided by the square root of this value.
-   **Role:** This term provides the "adaptive" part of the update, creating a per-parameter learning rate.
    -   If a parameter's gradients have been consistently large, $\hat{v}_t$ will be large, making the denominator large. This reduces the effective learning rate for that parameter, preventing it from taking steps that are too large and overshooting the minimum.
    -   If a parameter's gradients have been small or infrequent (e.g., for sparse features), $\hat{v}_t$ will be small, making the denominator small. This increases the effective learning rate for that parameter, allowing it to make more significant progress.

In essence, Adam uses the momentum-driven mean of gradients ($\hat{m}_t$) to suggest the update direction, and then it normalizes this update element-wise by the magnitude of recent gradients ($\sqrt{\hat{v}_t}$) to adapt the step size for each individual weight.

<br>

### **Solution to Question 3: The Necessity of Bias Correction in Adam**

**Problem Statement:** Explain why Adam's moment estimates are biased and how the correction term works.

**Solution:**

The moving averages for the first and second moments, $m_t$ and $v_t$, are initialized to zero vectors ($m_0 = 0, v_0 = 0$).

**Source of Bias:**
Let's examine the first moment update: $m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t$ (where $g_t = \nabla_W L$).
At the first time step ($t=1$):

$$
m_1 = \beta_1 m_0 + (1 - \beta_1) g_1 = (1 - \beta_1) g_1
$$

The expected value of the moving average $E[m_t]$ is an exponentially weighted average of the true expected gradients. However, because we initialize with zero, the early estimates are "biased" towards zero. For instance, since $\beta_1$ is typically 0.9, $m_1$ is only 10% of the first gradient $g_1$. This means the initial updates would be undesirably small if we used $m_t$ directly.

**The Correction Mechanism:**
The bias correction formula is $\hat{m}_t = \frac{m_t}{1 - \beta_1^t}$.
Let's analyze the denominator, $(1 - \beta_1^t)$:
-   **At early stages (small $t$):** When $t=1$, the correction factor is $1 / (1 - \beta_1)$. This scales up the biased estimate $m_1 = (1 - \beta_1)g_1$ to become $\hat{m}_1 = \frac{(1-\beta_1)g_1}{1-\beta_1} = g_1$. The correction effectively removes the zero-initialization bias in the first step. For the next few steps, the denominator remains small, providing a significant correction.
-   **At later stages (large $t$):** As $t$ increases, the term $\beta_1^t$ approaches zero (since $\beta_1 < 1$). Therefore, the denominator $(1 - \beta_1^t)$ approaches 1. At this point, the correction has a negligible effect, which is desirable because the moving average $m_t$ has had enough time to accumulate data and become a good, unbiased estimate of the true mean of the gradients.

This correction is crucial at the beginning of training to ensure that the initial steps are appropriately sized, preventing the optimizer from taking an overly cautious and slow start.

<br>

### **Solution to Question 4: The Impact of the Momentum Hyperparameter**

**Problem Statement:** Analyze the effect of the momentum term $\gamma$ when set to 0 and a value close to 1.

**Solution:**

The Momentum optimizer's velocity update is $v_t = \gamma v_{t-1} + \eta \nabla_W L$.

**1. Case: $\gamma = 0$**
If we set $\gamma = 0$, the velocity update equation becomes:

$$
v_t = (0) \cdot v_{t-1} + \eta \nabla_W L = \eta \nabla_W L
$$

The weight update is then $W \leftarrow W - v_t$, which becomes:

$$
W \leftarrow W - \eta \nabla_W L
$$

This is precisely the update rule for standard Gradient Descent. When $\gamma=0$, there is no "memory" of past gradients; the optimizer loses all momentum and relies only on the current local gradient.

**2. Case: $\gamma \approx 1$ (e.g., 0.999)**
When $\gamma$ is very close to 1, the term $\gamma v_{t-1}$ heavily dominates the velocity update.
-   **Physical Analogy:** This is equivalent to a very heavy ball rolling down a hill with very little friction.
-   **Benefits:** The high momentum allows the "ball" to power through flat regions (plateaus) and escape shallow local minima where the local gradient $\nabla_W L$ is very small. It maintains its speed and direction based on a long history of past gradients.
-   **Drawbacks:** The optimizer becomes less sensitive to the current gradient. If the heavy ball has built up a lot of speed, it may completely overshoot a narrow global minimum and fail to settle there. It can be difficult to slow down or change direction, which can lead to oscillations around the minimum or even divergence if the learning rate is not carefully tuned. Convergence can be slow as the optimizer struggles to shed its accumulated momentum near the solution.