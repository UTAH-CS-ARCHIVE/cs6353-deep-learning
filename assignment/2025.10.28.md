Hello class, üßë‚Äçüè´

Based on our introduction to Recurrent Neural Networks, I've prepared an assignment that covers the core mechanics and the fundamental challenges of this architecture. Please review the prompt and the model report that follows.

<br>

## Assignment: Analysis of Simple Recurrent Neural Networks

### Prompt

Write a technical report that provides a comprehensive explanation of a simple Recurrent Neural Network (RNN). Your report must address the following three points in detail:

1.  **Forward Propagation**: Write down and explain the two core mathematical equations that define the forward pass of an RNN at a single time step, $t$. Clearly define each term and explain the significance of **parameter sharing** across the time dimension.
2.  **Training Mechanism**: Describe the process of **Backpropagation Through Time (BPTT)**. Explain how this algorithm handles the recurrent structure of the network and how the gradients for the shared weight matrices are computed.
3.  **Core Limitation**: Define the **Long-Term Dependency Problem**. Explain mathematically why this issue arises from the BPTT process and discuss its practical consequences for training RNNs on long sequences.

<br>
<hr>
<br>

## Report: Mathematical Foundations and Limitations of Simple RNNs

### Introduction

Recurrent Neural Networks (RNNs) are a specialized class of neural networks designed to model sequential data, such as text and time series. Their defining feature is a recurrent loop that allows them to maintain a "memory" of past information. This report details the mathematical operations of a simple RNN's forward pass, explains its training via Backpropagation Through Time (BPTT), and analyzes the fundamental long-term dependency problem that limits its effectiveness on long sequences.

<br>

### 1. The RNN Forward Pass and Parameter Sharing üß†

The operation of an RNN is defined by a recurrence relation that updates the network's state at each time step. For a given time step $t$, the two core equations are:

**1. Hidden State Update:**
The hidden state $h_t$ is the network's memory. It's updated using the previous hidden state $h_{t-1}$ and the current input $x_t$.

$$
h_t = \tanh(W_{hh} h_{t-1} + W_{xh} x_t + b_h)
$$

* **$h_t$**: The hidden state vector at the current time step $t$.
* **$h_{t-1}$**: The hidden state vector from the previous time step $t-1$.
* **$x_t$**: The input vector at the current time step $t$.
* **$W_{xh}$**: The **input-to-hidden** weight matrix, which transforms the current input.
* **$W_{hh}$**: The **hidden-to-hidden** weight matrix, which transforms the previous hidden state. This is the recurrent connection.
* **$b_h$**: A bias term for the hidden state.
* **$\tanh$**: The hyperbolic tangent activation function, which keeps the hidden state values between -1 and 1.

**2. Output Calculation:**
The output at the current time step, $y_t$, is typically a function of the current hidden state.

$$
y_t = W_{hy} h_t + b_y
$$

* **$y_t$**: The output vector at time step $t$.
* **$W_{hy}$**: The **hidden-to-output** weight matrix, which maps the hidden state to the desired output space.
* **$b_y$**: A bias term for the output.

A crucial concept here is **parameter sharing**. The weight matrices ($W_{xh}, W_{hh}, W_{hy}$) and biases are **the same for all time steps**. The network learns one set of rules and applies it repeatedly as it processes the sequence. This makes the model computationally efficient and allows it to generalize to sequences of varying lengths.

<br>
<hr>
<br>

### 2. Training with Backpropagation Through Time (BPTT) üîÑ

To train an RNN, we cannot use standard backpropagation on the cyclic graph. Instead, we use Backpropagation Through Time (BPTT), which involves two main steps:

**1. Unrolling the Network:**
The recurrent network is conceptually "unrolled" into a deep feedforward network, where each time step of the sequence becomes a layer in the unrolled model. For a sequence of length $T$, this creates a $T$-layer deep network where the weights at each layer are shared.


**2. Applying Backpropagation:**
Once unrolled, the training proceeds as follows:
* The entire input sequence is fed through the unrolled network to compute the outputs and a total loss, $\mathcal{L}$, which is typically the sum of the losses at each time step ($\mathcal{L} = \sum_{t=1}^{T} \mathcal{L}_t$).
* The gradient of the total loss with respect to the weights is then calculated by backpropagating the error from the last time step ($T$) all the way to the first ($t=1$).
* Because the weights (e.g., $W_{hh}$) are shared across all time steps, the final gradient for that weight matrix is the **sum of the individual gradients** computed at each time step. For a weight matrix $W$, this is expressed as:
    $$
    \frac{\partial \mathcal{L}}{\partial W} = \sum_{t=1}^{T} \frac{\partial \mathcal{L}_t}{\partial W}
    $$
This aggregation step ensures that the weight update reflects its influence across the entire sequence.

<br>
<hr>
<br>

### 3. The Long-Term Dependency Problem üòü

The primary limitation of simple RNNs is their difficulty in learning **long-term dependencies**‚Äîthat is, connecting information across many time steps.

**Mathematical Cause:**
This problem is a direct consequence of BPTT. To calculate the gradient of the loss with respect to an early hidden state (e.g., $h_k$), the chain rule requires propagating the gradient back through all intermediate time steps. This involves a long product of Jacobian matrices. The key component in this product is the repeated multiplication by the hidden-to-hidden weight matrix, $W_{hh}$.

The gradient of the loss at a late time step $t$ with respect to a hidden state at an early time step $k$ depends on the term:

$$
\frac{\partial h_t}{\partial h_k} = \prod_{i=k+1}^{t} \frac{\partial h_i}{\partial h_{i-1}}
$$

Each term $\frac{\partial h_i}{\partial h_{i-1}}$ is proportional to the weight matrix $W_{hh}$. Therefore, this calculation involves multiplying $W_{hh}$ by itself many times.

* **Vanishing Gradients**: If the norms (or singular values) of $W_{hh}$ are less than 1, this product will shrink exponentially toward zero as the distance $(t-k)$ increases. The gradient signal from the distant past effectively vanishes, making it impossible for the model to learn relationships between distant events.
* **Exploding Gradients**: If the norms of $W_{hh}$ are greater than 1, this product will grow exponentially, causing the gradients to become enormous and leading to unstable training.

**Practical Consequences:**
Due to vanishing gradients, a simple RNN may struggle with tasks requiring long-term memory. For example, in the sentence "I grew up in France and I love their culture, so I speak fluent ___", the model needs to connect "France" to "French". If the sentence is long, the gradient signal from "France" might be too weak to influence the prediction at the end. This limitation was the primary motivation for developing more sophisticated recurrent architectures like LSTM and GRU.