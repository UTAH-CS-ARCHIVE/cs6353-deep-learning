## Assignment 7: A Comparative Study of Optimization Algorithms

**Instructions:** Answer the following questions based on the lecture material. Provide clear reasoning for your choices and interpretations.

<br>

**Question 1: The Rationale for Learning Rate Scheduling**

The lecture notes introduce Learning Rate Scheduling as a solution to the problems of a fixed learning rate.
1.  Briefly summarize the trade-off between using a high learning rate versus a low learning rate for the entire duration of training.
2.  The notes mention "Step Decay" as a common scheduling strategy. Describe this strategy and provide a simple mathematical formula or pseudo-code that defines the learning rate $\eta_e$ at a given epoch $e$, given an initial learning rate $\eta_0$, a decay factor $\gamma$, and a step size $S$ (in epochs).

<br>

**Question 2: Developing an Intuition for Optimizers**

The lecture provides analogies for SGD, SGD with Momentum, and Adam (a hiker in fog, a rolling ball, an expert hiker). Create a new, original analogy to describe the behavior and differences between these three optimizers. Justify why each part of your analogy corresponds to the characteristics of the respective algorithm.

<br>

**Question 3: Choosing the Right Optimizer for the Job**

Imagine you are working on two different deep learning projects. Based on the pros and cons discussed in the lecture, recommend an optimizer (SGD, SGD with Momentum, or Adam) for each scenario and justify your choice.

-   **Scenario A:** You are developing a completely new type of neural network architecture for a novel problem. The loss landscape is likely to be complex and unpredictable, and your primary goal is to quickly determine if the model can learn at all.
-   **Scenario B:** You are fine-tuning a well-known, state-of-the-art model (like a Vision Transformer) on a standard benchmark dataset (like ImageNet). Your goal is to achieve the highest possible validation accuracy, aiming to beat the existing record by a small margin. Extensive hyperparameter tuning is feasible.

<br>

**Question 4: Interpreting Experimental Loss Curves**

You run an experiment to compare the three optimizers on the same task, resulting in the following training loss curves:
-   **Optimizer X:** The loss drops extremely rapidly in the first few epochs but then plateaus and makes very slow progress, ending at a final loss of 0.45.
-   **Optimizer Y:** The loss curve is very noisy with significant oscillations. It decreases much more slowly than the others and ends at a final loss of 0.55 after the same number of epochs.
-   **Optimizer Z:** The loss curve is smoother than Y's and decreases more slowly than X's initially. However, it continues to decrease steadily and ultimately reaches the lowest final loss of 0.35.

Identify which optimizer (SGD, SGD with Momentum, Adam) most likely corresponds to X, Y, and Z. Justify your reasoning for each choice based on their known characteristics.

<br>
<br>

## Solution Report: Assignment 7

Below are the detailed solutions for the assignment on the comparative study of optimization algorithms.

<br>

### **Solution to Question 1: The Rationale for Learning Rate Scheduling**

**Problem Statement:** Explain the LR trade-off and formalize the Step Decay scheduler.

**Solution:**

1.  **Learning Rate Trade-off:**
    -   A **high learning rate** is advantageous at the beginning of training. The weights are far from their optimal values, and a large step size allows for rapid movement across the loss landscape, leading to faster initial convergence. However, as training progresses and the weights approach a minimum, a high learning rate can cause the updates to constantly overshoot the optimal point, leading to oscillations around the minimum and preventing convergence to the best possible solution.
    -   A **low learning rate** ensures that the weight updates are small and careful. This is ideal near a minimum, as it allows the optimizer to gently descend to the bottom of the loss valley without overshooting. However, if used from the start, the training process would be extremely slow, requiring a vast number of iterations to make significant progress.

2.  **Step Decay Formula:**
    Step Decay reduces the learning rate by a multiplicative factor at pre-defined epoch intervals. Given an initial learning rate $\eta_0$, a decay factor $\gamma$ (e.g., 0.1), and a step size $S$ (the number of epochs between decays), the learning rate $\eta_e$ at epoch $e$ can be defined as:

    $$
    \eta_e = \eta_0 \cdot \gamma^{\lfloor e / S \rfloor}
    $$
    
    Here, $\lfloor e / S \rfloor$ is the floor function, which calculates how many times the step size $S$ has been completed by epoch $e$. For every $S$ epochs that pass, this integer value increases by one, causing the learning rate to be multiplied by another factor of $\gamma$. For example, if $\eta_0=0.1$, $\gamma=0.1$, and $S=20$, the learning rate will be 0.1 for epochs 0-19, then 0.01 for epochs 20-39, then 0.001 for epochs 40-59, and so on.

<br>

### **Solution to Question 2: Developing an Intuition for Optimizers**

**Problem Statement:** Create a new analogy to explain the differences between SGD, Momentum, and Adam.

**Solution:**

Let's use the analogy of a boat trying to navigate to the deepest point in a lake.

-   **SGD (A Small Rowboat in the Wind):** The person in the rowboat has no memory or forward-planning. At any given moment, they look at the water's slope right next to the boat (the local gradient) and paddle once in that direction. The path is heavily influenced by momentary gusts of wind (noise from the mini-batch), causing the boat to move erratically. If the boat enters a long, narrow channel (a ravine), the wind might keep pushing it into the banks, making forward progress very slow.

-   **SGD with Momentum (A Heavy Ferry):** This boat is large and has a powerful engine, giving it significant momentum. When it starts moving in a direction, it tends to continue in that direction. Short-lived gusts of wind (gradient noise) have little effect on its course. In a narrow channel, even if the wind pushes it sideways, its forward momentum keeps it progressing along the channel's length. This makes its path much smoother and faster than the rowboat's.

-   **Adam (A Modern Speedboat with GPS and Thrusters):** This boat not only has a powerful engine for momentum (1st moment) but is also equipped with advanced sensors that measure water turbulence and depth changes (2nd moment/gradient variance). It uses this information to dynamically adjust its engine output and side thrusters. If it detects a lot of turbulence (high gradient variance), it slows down for more precise control. If the water is calm (low gradient variance), it speeds up. This allows it to navigate towards the deepest point with incredible speed and efficiency, automatically adapting its behavior to the local conditions.

<br>

### **Solution to Question 3: Choosing the Right Optimizer for the Job**

**Problem Statement:** Recommend an optimizer for two different scenarios.

**Solution:**

-   **Scenario A (Novel Architecture, Unproven Concept):**
    -   **Recommendation:** **Adam**.
    -   **Justification:** Adam is the ideal choice for this scenario. Its main strengths are rapid convergence and robustness with default hyperparameters. When exploring a new, potentially difficult loss landscape, Adam's adaptive per-parameter learning rates can automatically handle a wide range of issues (ravines, plateaus) without requiring extensive manual tuning of the learning rate. The primary goal is to get a signal of whether the model can learn anything at all, and Adam will provide the fastest path to that answer.

-   **Scenario B (Fine-tuning for State-of-the-Art):**
    -   **Recommendation:** **SGD with Momentum**.
    -   **Justification:** In this scenario, the goal is to achieve the absolute best performance, and we can afford to spend time on tuning. The lecture notes and empirical evidence from the research community suggest that while Adam converges faster, a meticulously tuned SGD with Momentum (often paired with a learning rate scheduler) can explore the loss landscape more thoroughly in the final stages of training and settle into a slightly better (lower and wider) minimum. Since the problem and architecture are well-understood, we can leverage existing knowledge about good hyperparameters and schedules to squeeze out that last fraction of a percent in accuracy, which is what matters when aiming for a state-of-the-art result.

<br>

### **Solution to Question 4: Interpreting Experimental Loss Curves**

**Problem Statement:** Match the optimizers (SGD, Momentum, Adam) to the described loss curves (X, Y, Z).

**Solution:**

-   **Optimizer Y is SGD:** The description of a very noisy, oscillating, and slowly decreasing loss curve is the classic signature of vanilla Stochastic Gradient Descent. The noise comes from the high variance in gradients from one mini-batch to the next, and the slow convergence is due to its inefficiency in navigating complex loss landscapes.

-   **Optimizer X is Adam:** The key characteristic of Adam is its extremely fast initial convergence. The description of the loss dropping rapidly at the start perfectly matches Adam's behavior. The fact that it plateaus and might not find the absolute best minimum is also a known trait; it finds a very good solution very quickly, but its adaptive nature can sometimes prevent it from settling into the sharpest minima that other methods might find with more time.

-   **Optimizer Z is SGD with Momentum:** This curve represents a middle ground that is consistent with Momentum. It is smoother and faster than SGD (Y) because the momentum term averages out the gradient noise and accelerates progress. It is initially slower than Adam (X) but ultimately achieves a better final loss value. This reflects the optimizer's ability to converge well while its accumulated velocity allows it to thoroughly explore the area around the minimum to find a better final resting point.