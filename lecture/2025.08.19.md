## [Lecture Note] Introduction & Mathematical Foundations Review

> Written by Hongseo Jang

### **Part 1: A Brief Introduction to Deep Learning**

#### **History and Evolution of Deep Learning**

Deep Learning, a subfield of Machine Learning, isn't as new as many people think. Its intellectual roots go back to the 1940s. The journey has been a rollercoaster of excitement, disillusionment, and recent breakthroughs.

- **The Dawn (1940s-1960s):** The story begins with the work of McCulloch and Pitts in 1943, who proposed a simplified mathematical model of a neuron. This laid the groundwork for neural networks. A few years later, Frank Rosenblatt developed the **Perceptron**, an algorithm for supervised learning of binary classifiers. This was a single-layer neural network, and its simplicity was both its strength and its ultimate limitation.

- **The First "AI Winter" (1970s-1980s):** The initial excitement hit a wall. In 1969, Minsky and Papert's book "Perceptrons" highlighted the model's significant limitations, famously showing it couldn't solve the XOR problem. This led to a period of reduced funding and interest in neural network research, often called the first AI winter. However, crucial theoretical work continued. The concept of **backpropagation**, the algorithm that is the cornerstone of training deep networks today, was explored by various researchers, but it was Paul Werbos's Ph.D. thesis in 1974 that laid out its application to neural networks.

- **The Rise of Connectionism (1980s-1990s):** Backpropagation was rediscovered and popularized in 1986 by Rumelhart, Hinton, and Williams. This enabled the training of multi-layered networks, which could solve more complex problems than the single-layer perceptron. This era saw the development of key architectures like **Convolutional Neural Networks (CNNs)** by Yann LeCun for image recognition (LeNet-5 for digit recognition was a milestone) and **Recurrent Neural Networks (RNNs)** for sequential data.

- **The Second "AI Winter" (Late 1990s - Early 2000s):** Despite progress, training deep networks remained challenging. The **vanishing gradient problem** made it difficult for backpropagation to work effectively in deep networks. Other machine learning methods, such as Support Vector Machines (SVMs), often performed better and were mathematically more elegant, leading to another decline in the popularity of neural networks.

- **The Deep Learning Revolution (2006-Present):** The game changed in the mid-2000s. A few key factors converged:
    1.  **Algorithmic Improvements:** Hinton et al. introduced "Deep Belief Networks" in 2006, showing that networks could be pre-trained layer-by-layer, which helped overcome some of the optimization challenges. New activation functions like ReLU (Rectified Linear Unit) were introduced, helping to mitigate the vanishing gradient problem.
    2.  **Big Data:** The internet boom generated massive datasets (like ImageNet), which are essential for training deep models effectively. Deep learning models are data-hungry, and this was the fuel they needed.
    3.  **Hardware Advancements:** The realization that **Graphics Processing Units (GPUs)** were highly effective for the matrix/vector computations inherent in deep learning was a massive breakthrough. GPUs provided the parallel computing power needed to train deep networks in a reasonable amount of time.

The turning point was in 2012 when a CNN called **AlexNet** (developed by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton) won the ImageNet Large Scale Visual Recognition Challenge by a huge margin. This event marked the beginning of the current deep learning boom.

<br>

#### **Key Application Areas**

Deep Learning has become ubiquitous, achieving state-of-the-art results in many domains:

-   **Computer Vision:** This is arguably the field most transformed by deep learning. Applications include:
    * Image Classification (e.g., identifying objects in photos).
    * Object Detection and Segmentation (e.g., drawing bounding boxes around cars and pedestrians for autonomous driving).
    * Facial Recognition and Style Transfer.

-   **Natural Language Processing (NLP):** Deep learning models have revolutionized how machines understand and generate human language.
    * Machine Translation (e.g., Google Translate).
    * Sentiment Analysis (e.g., determining if a product review is positive or negative).
    * Chatbots and Virtual Assistants (e.g., Siri, Alexa).
    * Text Generation (e.g., Large Language Models like GPT).

-   **Speech Recognition:** Converting spoken language into text, now a standard feature in smartphones and smart home devices.

-   **Autonomous Systems:** Self-driving cars heavily rely on deep learning for perceiving their environment and making driving decisions.

-   **Healthcare:** Medical image analysis (e.g., detecting tumors in MRI scans), drug discovery, and genomic sequencing.

<br>

---

<br>

### **Part 2: Mathematical Foundations Review**

A solid understanding of a few key mathematical areas is crucial for deep learning. We're not just using libraries like TensorFlow or PyTorch as black boxes; understanding the underlying math helps in designing, debugging, and optimizing models.

<br>

#### **1. Linear Algebra**

At its core, deep learning is a series of transformations on numerical data. Linear algebra provides the language and tools to describe and perform these transformations.

-   **Data as Vectors:** We represent data points—be it an image, a user profile, or a word—as **vectors**. A vector is simply a list of numbers. For example, a grayscale image of size 28x28 pixels can be "unrolled" into a vector of $28 \times 28 = 784$ dimensions. We operate within a **vector space**, which is the collection of all possible vectors of a certain dimension.

-   **Transformations as Matrices:** A **matrix** is a grid of numbers that acts on a vector to transform it. This transformation can be a rotation, a scaling, or a shear. In a neural network, the "weights" of a layer are stored in a matrix. The input data (a vector) is multiplied by the weights matrix to produce the output for that layer.
    * **Matrix Multiplication:** If we have an input vector $x$ and a weight matrix $W$, the operation $z = Wx$ transforms $x$ into a new vector $z$. This is the fundamental operation in a neural network layer.
    * **Transpose:** The transpose of a matrix, denoted as $A^T$, is found by flipping the matrix over its main diagonal. This operation is frequently used in various calculations, especially when dealing with gradients.

-   **Eigenvalues and Eigenvectors:** For a given square matrix $A$, an **eigenvector** $v$ is a non-zero vector that, when multiplied by $A$, only changes in scale, not direction. The amount by which it scales is the **eigenvalue** $\lambda$. This relationship is captured by the equation:
    
    $$
    Av = \lambda v
    $$
    
    In the context of machine learning, eigenvalues and eigenvectors are fundamental to techniques like Principal Component Analysis (PCA), where they help identify the most important directions (principal components) in the data, effectively reducing its dimensionality while preserving variance.

<br>

#### **2. Calculus**

Calculus, specifically differential calculus, is the engine of optimization in deep learning. It's how models learn from data.

-   **Partial Derivatives:** Neural networks are essentially very complex, high-dimensional functions with millions of parameters (the weights). To optimize these parameters, we need to know how a small change in one parameter affects the overall output error (or "loss"). A **partial derivative**, $\frac{\partial f}{\partial x_i}$, tells us the rate of change of a multi-variable function $f(x_1, x_2, ..., x_n)$ with respect to just one of its variables, $x_i$, while holding all other variables constant.

-   **The Gradient ($ \nabla f $):** The gradient is the vector of all partial derivatives of a function. For a function $f(x, y, z)$, the gradient is:
    
    $$
    \nabla f = \left( \frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}, \frac{\partial f}{\partial z} \right)
    $$
    
    Geometrically, the gradient vector $\nabla f$ at a particular point points in the direction of the **steepest ascent** of the function at that point. To learn, we want to *minimize* our loss function. Therefore, we move in the direction *opposite* to the gradient. This is the core idea of the **gradient descent** optimization algorithm.

-   **The Chain Rule:** Neural networks are composite functions, meaning they are functions nested within functions (layer after layer). The chain rule is a formula to compute the derivative of such composite functions. If we have a loss $L$ that depends on the output of a neuron $y$, which in turn depends on a weight $w$, the chain rule allows us to calculate the derivative of the loss with respect to the weight:
    
    $$
    \frac{\partial L}{\partial w} = \frac{\partial L}{\partial y} \cdot \frac{\partial y}{\partial w}
    $$
    
    This rule is applied recursively backwards from the final output layer to the first input layer to calculate the gradient for every weight in the network. This entire process is what we call **backpropagation**.

<br>

#### **3. Probability Theory**

Probability theory provides the framework for dealing with the uncertainty inherent in machine learning. It helps us model our data and quantify the confidence in our predictions.

-   **Random Variables:** A random variable is a variable whose value is a numerical outcome of a random phenomenon. For instance, the outcome of a coin flip can be a random variable that takes the value 1 for heads and 0 for tails.

-   **Probability Distributions:** A probability distribution describes the likelihood of a random variable taking on each of its possible values. Key distributions include:
    * **Bernoulli Distribution:** Represents the outcome of a single trial with two possible outcomes (e.g., success/failure, yes/no). It's the building block for binary classification problems.
    * **Normal (Gaussian) Distribution:** The classic "bell curve." Many natural phenomena follow this distribution. It's often used to model the distribution of errors or to initialize weights in a neural network.

-   **Conditional Probability and Bayes' Theorem:**
    * **Conditional Probability**, $P(A|B)$, is the probability of event A occurring *given that* event B has already occurred.
    * **Bayes' Theorem** is a fundamental formula that allows us to update our beliefs in light of new evidence. It relates a conditional probability to its inverse. The theorem states:

    $$
    P(A|B) = \frac{P(B|A)P(A)}{P(B)}
    $$

    In this formula:
    * $P(A|B)$ is the **posterior** probability: our updated belief about A after observing B.
    * $P(B|A)$ is the **likelihood**: the probability of observing B if A is true.
    * $P(A)$ is the **prior** probability: our initial belief about A.
    * $P(B)$ is the **evidence**: the total probability of observing B.