# [Lecture Note] Development Environment and Library Basics

> Written by Hongseo Jang

## 1. Setting Up the Deep Learning Development Environment

### 1.1. Anaconda & Environment Management
Anaconda is an open-source distribution of Python and R, primarily used for scientific computing, data science, and machine learning. Its key advantage is its package manager, `conda`.

**Why use Anaconda?**
- **Package Management**: Simplifies the process of installing, updating, and managing libraries and their dependencies. It resolves complex dependency conflicts automatically.
- **Environment Isolation**: Allows us to create isolated environments for different projects. This is crucial because different projects might require different versions of libraries (e.g., one project needs TensorFlow 2.1, another needs 2.8). Without environments, these would conflict.

**Basic Conda Commands:**
- **Create a new environment**:
  `conda create --name dl_env python=3.9`
  (This creates an environment named `dl_env` with Python 3.9)
- **Activate the environment**:
  `conda activate dl_env`
  (You must activate an environment before installing packages or running code in it.)
- **Deactivate the environment**:
  `conda deactivate`
- **Install packages**:
  `conda install numpy pandas matplotlib` or `pip install <package_name>`

<br>

### 1.2. Jupyter Notebook
Jupyter Notebook is an interactive web-based computational environment. It allows you to create and share documents that contain live code, equations, visualizations, and narrative text.

**Why is it useful for Deep Learning?**
- **Interactivity**: You can run code in small chunks (cells), making it easy to test ideas, debug, and see immediate results.
- **Visualization**: Integrates seamlessly with plotting libraries like Matplotlib and Seaborn, allowing you to visualize data, model architecture, and training progress directly within the notebook.
- **Documentation**: You can mix code with explanations (using Markdown), which is perfect for creating reports, tutorials, and shareable experiments.

<br>

### 1.3. Installing Deep Learning Frameworks
Once the conda environment is activated, we can install the core frameworks.

- **PyTorch Installation**: The command is usually obtained from the official PyTorch website to ensure compatibility with your system's CUDA version (for GPU acceleration).
  `pip install torch torchvision torchaudio` (Example for a CPU-only version)

- **TensorFlow Installation**:
  `pip install tensorflow` (This typically installs the latest stable version with GPU support if the necessary drivers are present).

<br>
<br>

## 2. Practical Session: NumPy for Numerical Operations

NumPy (Numerical Python) is the fundamental package for scientific computing in Python. It provides a high-performance multidimensional array object and tools for working with these arrays. DL frameworks are heavily inspired by NumPy's API.

### 2.1. Vectors (1D Arrays)
A vector can be represented as a 1D NumPy array.

- **Creation**: `v = np.array([1, 2, 3])`
- **Shape**: `v.shape` -> `(3,)`
- **Basic Operations**:
  - Let `v1 = np.array([1, 2, 3])` and `v2 = np.array([4, 5, 6])`.
  - **Addition**: `v1 + v2` -> `[5, 7, 9]`
  - **Scalar Multiplication**: `v1 * 2` -> `[2, 4, 6]`
  - **Element-wise Product (Hadamard Product)**: `v1 * v2` -> `[4, 10, 18]`
  - **Dot Product**:
    The dot product of two vectors $\mathbf{a}$ and $\mathbf{b}$ is defined as:
    $$
    \mathbf{a} \cdot \mathbf{b} = \sum_{i=1}^{n} a_i b_i
    $$
    In code: `np.dot(v1, v2)` or `v1 @ v2` -> `1*4 + 2*5 + 3*6 = 32`

<br>

### 2.2. Matrices (2D Arrays)
A matrix is represented as a 2D NumPy array.

- **Creation**: `m = np.array([[1, 2, 3], [4, 5, 6]])`
- **Shape**: `m.shape` -> `(2, 3)` (2 rows, 3 columns)
- **Basic Operations**:
  - Let `m1 = np.array([[1, 2], [3, 4]])` and `m2 = np.array([[5, 6], [7, 8]])`.
  - **Addition**: `m1 + m2` -> `[[6, 8], [10, 12]]`
  - **Element-wise Product**: `m1 * m2` -> `[[5, 12], [21, 32]]`
  - **Matrix Multiplication**: This is different from the element-wise product. The number of columns in the first matrix must equal the number of rows in the second. If $A$ is an $m \times n$ matrix and $B$ is an $n \times p$ matrix, their product $C = AB$ is an $m \times p$ matrix where:
    $$
    C_{ij} = \sum_{k=1}^{n} A_{ik} B_{kj}
    $$
    In code: `np.matmul(m1, m2)` or `m1 @ m2` -> `[[1*5+2*7, 1*6+2*8], [3*5+4*7, 3*6+4*8]]` -> `[[19, 22], [43, 50]]`

<br>
<br>

## 3. Practical Session: Tensor Fundamentals

A **Tensor** is the primary data structure used in deep learning frameworks like PyTorch and TensorFlow. It's an N-dimensional array, very similar to a NumPy `ndarray`.

**Key Differences from NumPy Arrays:**
1.  **GPU Acceleration**: Tensors can be moved to a GPU to perform massive parallel computations, which is essential for training deep neural networks.
2.  **Automatic Differentiation**: Tensors can keep track of the operations performed on them, allowing for the automatic computation of gradients (derivatives). This is the core of backpropagation.

### 3.1. Tensor Creation and Basic Operations

**PyTorch**
```python
import torch

# Create a tensor from a list
t1 = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)

# Create a tensor from a NumPy array
import numpy as np
arr = np.array([5, 6])
t2 = torch.from_numpy(arr)

# Basic Operations
t_sum = t1 + t1
t_mul = t1 * 2
# Matrix multiplication
t_matmul = torch.matmul(t1, t1)
```
